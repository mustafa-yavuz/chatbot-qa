{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "\n",
    "with open(\"chatbot_train.txt\", \"rb\") as f:   #list of tuples\n",
    "    train =  pickle.load(f)\n",
    "with open(\"chatbot_test.txt\", \"rb\") as f:   \n",
    "    test =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test data into a dataframe\n",
    "data = train + test\n",
    "\n",
    "df_dict = {\"story\":[' '.join(tp[0]) for tp in data],\"question\":[' '.join(tp[1]) for tp in data],\"answer\":[tp[2] for tp in data]}\n",
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Sandra in the hallway ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the office ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "1  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "2  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "3  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "4  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "\n",
       "                      question answer  \n",
       "0   Is Sandra in the hallway ?     no  \n",
       "1  Is Daniel in the bathroom ?     no  \n",
       "2    Is Daniel in the office ?     no  \n",
       "3   Is Daniel in the bedroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?    yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus to find vocabulary \n",
    "corpus = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    whole_text = df['story'][i] +' '+ df['question'][i] +' '+ df['answer'][i]\n",
    "    corpus.append(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern = r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\.\")\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'sandra',\n",
       " 'journeyed',\n",
       " 'bedroom',\n",
       " 'is',\n",
       " 'in',\n",
       " 'hallway',\n",
       " '?',\n",
       " 'no',\n",
       " 'went',\n",
       " 'back',\n",
       " 'daniel',\n",
       " 'kitchen',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'football',\n",
       " 'there',\n",
       " 'yes',\n",
       " 'john',\n",
       " 'travelled',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'apple',\n",
       " 'put',\n",
       " 'down',\n",
       " 'grabbed',\n",
       " 'left',\n",
       " 'dropped',\n",
       " 'took',\n",
       " 'milk',\n",
       " 'discarded']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a placeholder for when using keras pad_sequences\n",
    "\n",
    "vocab_len = len(vocabulary) + 1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to create vocabulary\n",
    "\n",
    "#from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "#tokenizer = Tokenizer(filters=[])\n",
    "\n",
    "#for text in [df.story.values,df.question.values,df.answer.values]:\n",
    "#    tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the maximum story length for padding seuqences\n",
    "\n",
    "max_story_len = max([len(tp[0]) for tp in data]) \n",
    "max_question_len = max([len(tp[1]) for tp in data]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(np.array([len(tp[0]) for tp in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoding words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index # lower-cased automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"story\":[' '.join(tp[0]) for tp in train],\"question\":[' '.join(tp[1]) for tp in train],\"answer\":[tp[2] for tp in train]}\n",
    "train_df = pd.DataFrame(train_dict)\n",
    "\n",
    "test_dict = {\"story\":[' '.join(tp[0]) for tp in test],\"question\":[' '.join(tp[1]) for tp in test],\"answer\":[tp[2] for tp in test]}\n",
    "test_df = pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Sandra in the hallway ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the office ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "1  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "2  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "3  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "4  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "\n",
       "                      question answer  \n",
       "0   Is Sandra in the hallway ?     no  \n",
       "1  Is Daniel in the bathroom ?     no  \n",
       "2    Is Daniel in the office ?     no  \n",
       "3   Is Daniel in the bedroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?    yes  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the kitchen ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the kitchen ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the garden ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary got the milk there . John moved to the be...   \n",
       "1  Mary got the milk there . John moved to the be...   \n",
       "2  Mary got the milk there . John moved to the be...   \n",
       "3  Mary got the milk there . John moved to the be...   \n",
       "4  Mary got the milk there . John moved to the be...   \n",
       "\n",
       "                      question answer  \n",
       "0     Is John in the kitchen ?     no  \n",
       "1     Is John in the kitchen ?     no  \n",
       "2      Is John in the garden ?    yes  \n",
       "3  Is Daniel in the bathroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?     no  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_story_and_questions(dframe, tokenizer):\n",
    "    \n",
    "    story = tokenizer.texts_to_sequences(dframe.story.values)\n",
    "    question = tokenizer.texts_to_sequences(dframe.question.values)\n",
    "\n",
    "    story = sequence.pad_sequences(story, maxlen=156)\n",
    "    question = sequence.pad_sequences(question, maxlen=6)\n",
    "    \n",
    "    return story, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train = compute_story_and_questions(train_df,tokenizer)\n",
    "inputs_test, questions_test = compute_story_and_questions(test_df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_answer(dframe):\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for yes_no in dframe.answer.values:\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)    \n",
    "        y[word_index[yes_no]] = 1\n",
    "        answers.append(y)\n",
    "    \n",
    "    return np.array(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_train = compute_answer(train_df)\n",
    "answers_test = compute_answer(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0., 4988.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0., 5012.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_train) # number of yes and no in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs ( story and question ) \n",
    "# creating placeholders for inputs\n",
    "\n",
    "input_sequence = Input(shape = (max_story_len,))\n",
    "input_question = Input(shape = (max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input encoders m, c and question encoder\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 156, 64)\n",
    "encoder_m = Sequential()\n",
    "encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=156))\n",
    "encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 156, 6)\n",
    "encoder_c = Sequential()\n",
    "encoder_c.add(Embedding(input_dim=vocab_len,output_dim=6,input_length=156))\n",
    "encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 6, 64)\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=6))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding sequences\n",
    "\n",
    "# passing place holders through encoders\n",
    "result_m = encoder_m(input_sequence) \n",
    "result_c = encoder_c(input_sequence)\n",
    "result_q = question_encoder(input_question)\n",
    "\n",
    "dt = dot([result_m, result_q], axes=(2, 2))\n",
    "p = Activation('softmax')(dt)\n",
    "\n",
    "# adding the p matrix with the input vector c sequence\n",
    "o = add([p, result_c])  # (samples, 156, 6)\n",
    "o = Permute((2, 1))(o)  # (samples, 6, 156)\n",
    "\n",
    "# concatenating the o matrix with the question vector sequence\n",
    "W = concatenate([o,result_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing W with RNN (LSTM)\n",
    "W = LSTM(32)(W)  \n",
    "\n",
    "# Regularization \n",
    "W = Dropout(0.5)(W)\n",
    "W = Dense(vocab_len)(W)  # (batch_size, vocab_size)\n",
    "\n",
    "# outputing a probability distribution over the vocabulary\n",
    "W = Activation('softmax')(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "model = Model([input_sequence, input_question], outputs = W)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 156, 64)      2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 156, 6)       228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WorkPC\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.9237 - accuracy: 0.5012 - val_loss: 0.7031 - val_accuracy: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 3s 328us/step - loss: 0.7044 - accuracy: 0.4959 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 3s 327us/step - loss: 0.6959 - accuracy: 0.5039 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 3s 329us/step - loss: 0.6958 - accuracy: 0.4897 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 3s 329us/step - loss: 0.6948 - accuracy: 0.4967 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 3s 330us/step - loss: 0.6944 - accuracy: 0.4998 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 3s 329us/step - loss: 0.6943 - accuracy: 0.5014 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 3s 329us/step - loss: 0.6947 - accuracy: 0.4959 - val_loss: 0.6952 - val_accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 3s 334us/step - loss: 0.6947 - accuracy: 0.4969 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.6944 - accuracy: 0.4939 - val_loss: 0.6947 - val_accuracy: 0.5030\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.6938 - accuracy: 0.5027 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.6942 - accuracy: 0.4923 - val_loss: 0.6939 - val_accuracy: 0.4730\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.6942 - accuracy: 0.4987 - val_loss: 0.6957 - val_accuracy: 0.4970\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 4s 357us/step - loss: 0.6937 - accuracy: 0.5024 - val_loss: 0.6949 - val_accuracy: 0.4980\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 4s 357us/step - loss: 0.6821 - accuracy: 0.5559 - val_loss: 0.6546 - val_accuracy: 0.5980\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.5581 - accuracy: 0.7357 - val_loss: 0.4621 - val_accuracy: 0.8030\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 4s 357us/step - loss: 0.4525 - accuracy: 0.8090 - val_loss: 0.4156 - val_accuracy: 0.8150\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.4189 - accuracy: 0.8283 - val_loss: 0.4005 - val_accuracy: 0.8320\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3910 - accuracy: 0.8424 - val_loss: 0.3906 - val_accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.3825 - accuracy: 0.8433 - val_loss: 0.3847 - val_accuracy: 0.8300\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3666 - accuracy: 0.8488 - val_loss: 0.3788 - val_accuracy: 0.8340\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3556 - accuracy: 0.8556 - val_loss: 0.3778 - val_accuracy: 0.8360\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3537 - accuracy: 0.8530 - val_loss: 0.3599 - val_accuracy: 0.8480\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.3441 - accuracy: 0.8551 - val_loss: 0.3648 - val_accuracy: 0.8360\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3384 - accuracy: 0.8547 - val_loss: 0.3623 - val_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.3285 - accuracy: 0.8635 - val_loss: 0.3543 - val_accuracy: 0.8320\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.3277 - accuracy: 0.8595 - val_loss: 0.3476 - val_accuracy: 0.8460\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3228 - accuracy: 0.8589 - val_loss: 0.3388 - val_accuracy: 0.8430\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.3195 - accuracy: 0.8619 - val_loss: 0.3410 - val_accuracy: 0.8420\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.3156 - accuracy: 0.8645 - val_loss: 0.3375 - val_accuracy: 0.8480\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 4s 356us/step - loss: 0.3118 - accuracy: 0.8620 - val_loss: 0.3346 - val_accuracy: 0.8540\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.3081 - accuracy: 0.8645 - val_loss: 0.3337 - val_accuracy: 0.8470\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.3045 - accuracy: 0.8661 - val_loss: 0.3305 - val_accuracy: 0.8480\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.3027 - accuracy: 0.8668 - val_loss: 0.3354 - val_accuracy: 0.8470\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.3020 - accuracy: 0.8657 - val_loss: 0.3369 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2983 - accuracy: 0.8672 - val_loss: 0.3361 - val_accuracy: 0.8440\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.3002 - accuracy: 0.8675 - val_loss: 0.3444 - val_accuracy: 0.8450\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2996 - accuracy: 0.8675 - val_loss: 0.3318 - val_accuracy: 0.8400\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2976 - accuracy: 0.8662 - val_loss: 0.3321 - val_accuracy: 0.8420\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2980 - accuracy: 0.8690 - val_loss: 0.3260 - val_accuracy: 0.8490\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2964 - accuracy: 0.8693 - val_loss: 0.3444 - val_accuracy: 0.8430\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2890 - accuracy: 0.8706 - val_loss: 0.3522 - val_accuracy: 0.8490\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2901 - accuracy: 0.8711 - val_loss: 0.3493 - val_accuracy: 0.8410\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2972 - accuracy: 0.8706 - val_loss: 0.3392 - val_accuracy: 0.8440\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.2913 - accuracy: 0.8713 - val_loss: 0.3564 - val_accuracy: 0.8380\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 4s 363us/step - loss: 0.2891 - accuracy: 0.8748 - val_loss: 0.3697 - val_accuracy: 0.8370\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 4s 367us/step - loss: 0.2929 - accuracy: 0.8711 - val_loss: 0.3354 - val_accuracy: 0.8440\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 4s 364us/step - loss: 0.2869 - accuracy: 0.8707 - val_loss: 0.3293 - val_accuracy: 0.8500\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2881 - accuracy: 0.8725 - val_loss: 0.3505 - val_accuracy: 0.8330\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2899 - accuracy: 0.8725 - val_loss: 0.3333 - val_accuracy: 0.8440\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2851 - accuracy: 0.8734 - val_loss: 0.3429 - val_accuracy: 0.8320\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2887 - accuracy: 0.8724 - val_loss: 0.3406 - val_accuracy: 0.8470\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2846 - accuracy: 0.8745 - val_loss: 0.3503 - val_accuracy: 0.8390\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2795 - accuracy: 0.8759 - val_loss: 0.3331 - val_accuracy: 0.8420\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2829 - accuracy: 0.8778 - val_loss: 0.3407 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2797 - accuracy: 0.8752 - val_loss: 0.3481 - val_accuracy: 0.8430\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2812 - accuracy: 0.8768 - val_loss: 0.3583 - val_accuracy: 0.8190\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2773 - accuracy: 0.8767 - val_loss: 0.3596 - val_accuracy: 0.8380\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2779 - accuracy: 0.8773 - val_loss: 0.3381 - val_accuracy: 0.8440\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2759 - accuracy: 0.8805 - val_loss: 0.3467 - val_accuracy: 0.8410\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2793 - accuracy: 0.8774 - val_loss: 0.3566 - val_accuracy: 0.8360\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2742 - accuracy: 0.8800 - val_loss: 0.3730 - val_accuracy: 0.8370\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2731 - accuracy: 0.8814 - val_loss: 0.3660 - val_accuracy: 0.8320\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2733 - accuracy: 0.8799 - val_loss: 0.3563 - val_accuracy: 0.8340\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 4s 365us/step - loss: 0.2740 - accuracy: 0.8802 - val_loss: 0.3664 - val_accuracy: 0.8250\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2748 - accuracy: 0.8787 - val_loss: 0.3816 - val_accuracy: 0.8300\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2694 - accuracy: 0.8853 - val_loss: 0.3816 - val_accuracy: 0.8410\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2702 - accuracy: 0.8832 - val_loss: 0.3683 - val_accuracy: 0.8420\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2637 - accuracy: 0.8864 - val_loss: 0.3944 - val_accuracy: 0.8360\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2676 - accuracy: 0.8821 - val_loss: 0.3628 - val_accuracy: 0.8400\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2648 - accuracy: 0.8845 - val_loss: 0.3616 - val_accuracy: 0.8390\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 4s 358us/step - loss: 0.2669 - accuracy: 0.8867 - val_loss: 0.3668 - val_accuracy: 0.8380\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2653 - accuracy: 0.8880 - val_loss: 0.3630 - val_accuracy: 0.8370\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2558 - accuracy: 0.8884 - val_loss: 0.3782 - val_accuracy: 0.8370\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2619 - accuracy: 0.8870 - val_loss: 0.3809 - val_accuracy: 0.8420\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2608 - accuracy: 0.8896 - val_loss: 0.3611 - val_accuracy: 0.8470\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2554 - accuracy: 0.8916 - val_loss: 0.3834 - val_accuracy: 0.8380\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2560 - accuracy: 0.8913 - val_loss: 0.3743 - val_accuracy: 0.8370\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2554 - accuracy: 0.8910 - val_loss: 0.3704 - val_accuracy: 0.8420\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2488 - accuracy: 0.8950 - val_loss: 0.3701 - val_accuracy: 0.8380\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2550 - accuracy: 0.8944 - val_loss: 0.3859 - val_accuracy: 0.8330\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2504 - accuracy: 0.8923 - val_loss: 0.3746 - val_accuracy: 0.8430\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2501 - accuracy: 0.8929 - val_loss: 0.3821 - val_accuracy: 0.8390\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2474 - accuracy: 0.8933 - val_loss: 0.3811 - val_accuracy: 0.8440\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2425 - accuracy: 0.8962 - val_loss: 0.3744 - val_accuracy: 0.8460\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2458 - accuracy: 0.8980 - val_loss: 0.3778 - val_accuracy: 0.8460\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2499 - accuracy: 0.8968 - val_loss: 0.3843 - val_accuracy: 0.8460\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2361 - accuracy: 0.8990 - val_loss: 0.3869 - val_accuracy: 0.8370\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2406 - accuracy: 0.8993 - val_loss: 0.3934 - val_accuracy: 0.8470\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2402 - accuracy: 0.8977 - val_loss: 0.4048 - val_accuracy: 0.8300\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2334 - accuracy: 0.9007 - val_loss: 0.4218 - val_accuracy: 0.8410\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2376 - accuracy: 0.9022 - val_loss: 0.3939 - val_accuracy: 0.8410\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 4s 362us/step - loss: 0.2339 - accuracy: 0.9023 - val_loss: 0.4118 - val_accuracy: 0.8440\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2371 - accuracy: 0.9036 - val_loss: 0.4207 - val_accuracy: 0.8400\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2319 - accuracy: 0.9051 - val_loss: 0.4403 - val_accuracy: 0.8380\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 4s 359us/step - loss: 0.2325 - accuracy: 0.9029 - val_loss: 0.4269 - val_accuracy: 0.8410\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2279 - accuracy: 0.9047 - val_loss: 0.4217 - val_accuracy: 0.8410\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2265 - accuracy: 0.9058 - val_loss: 0.3912 - val_accuracy: 0.8360\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.2187 - accuracy: 0.9115 - val_loss: 0.4275 - val_accuracy: 0.8450\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 4s 361us/step - loss: 0.2285 - accuracy: 0.9039 - val_loss: 0.4168 - val_accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[inputs_train,questions_train],\n",
    "                    y=answers_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "model.save(\"100_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predictions for test set\n",
    "predictions = model.predict(([inputs_test, questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "story       Mary got the milk there . John moved to the be...\n",
       "question                             Is John in the kitchen ?\n",
       "answer                                                     no\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of the answer:  0.99936205\n"
     ]
    }
   ],
   "source": [
    "# generating a prediction from model for first story/question/answer\n",
    "val_max = np.argmax(predictions[140])\n",
    "\n",
    "for key, val in word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of the answer: \", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'left',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.',\n",
       " 'John',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hallway',\n",
       " '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing our own cases, we must stick to the current vocabulary\n",
    "\n",
    "my_story = \"Mary left the bedroom . John dropped the football in the hallway .\"\n",
    "my_story.split() # punctuation is seperated as in format as it was trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'bedroom', '?']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question = \"Is the football in the bedroom ?\"\n",
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test cases. same format as our data (tuple)\n",
    "my_data = [(my_story.split(),my_question.split(),'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary left the bedroom . John dropped the footb...</td>\n",
       "      <td>Is the football in the bedroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary left the bedroom . John dropped the footb...   \n",
       "\n",
       "                           question answer  \n",
       "0  Is the football in the bedroom ?     no  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {\"story\":[' '.join(tp[0]) for tp in my_data],\n",
    "           \"question\":[' '.join(tp[1]) for tp in my_data],\n",
    "           \"answer\":[tp[2] for tp in my_data]}\n",
    "\n",
    "my_df = pd.DataFrame(my_dict)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story , my_question = compute_story_and_questions(my_df,tokenizer)\n",
    "my_answer = compute_answer(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        33,  4,  9,  6, 25, 34,  4, 22, 11,  4, 12,  6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 22, 11,  4,  9, 13]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of the answer:  0.99936205\n"
     ]
    }
   ],
   "source": [
    "my_prediction = model.predict(([my_story, my_question]))\n",
    "\n",
    "val_max = np.argmax(my_prediction[0])\n",
    "\n",
    "for key, val in word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of the answer: \", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
