{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "\n",
    "with open(\"train.txt\", \"rb\") as f:   #list of tuples\n",
    "    train =  pickle.load(f)\n",
    "with open(\"test.txt\", \"rb\") as f:   \n",
    "    test =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test data into a dataframe\n",
    "data = train + test\n",
    "\n",
    "df_dict = {\"story\":[' '.join(tp[0]) for tp in data],\"question\":[' '.join(tp[1]) for tp in data],\"answer\":[tp[2] for tp in data]}\n",
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"question\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Sandra in the hallway ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the office ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "1  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "2  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "3  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "4  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "\n",
       "                      question answer  \n",
       "0   Is Sandra in the hallway ?     no  \n",
       "1  Is Daniel in the bathroom ?     no  \n",
       "2    Is Daniel in the office ?     no  \n",
       "3   Is Daniel in the bedroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?    yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus to find vocabulary \n",
    "corpus = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    whole_text = df['story'][i] +' '+ df['question'][i] +' '+ df['answer'][i]\n",
    "    corpus.append(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using countvectorizer to find the vocabulary\n",
    "vectorizer = CountVectorizer(token_pattern = r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\.\")\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'sandra',\n",
       " 'journeyed',\n",
       " 'bedroom',\n",
       " 'is',\n",
       " 'in',\n",
       " 'hallway',\n",
       " '?',\n",
       " 'no',\n",
       " 'went',\n",
       " 'back',\n",
       " 'daniel',\n",
       " 'kitchen',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'football',\n",
       " 'there',\n",
       " 'yes',\n",
       " 'john',\n",
       " 'travelled',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'apple',\n",
       " 'put',\n",
       " 'down',\n",
       " 'grabbed',\n",
       " 'left',\n",
       " 'dropped',\n",
       " 'took',\n",
       " 'milk',\n",
       " 'discarded']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words in vocabulary\n",
    "list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a placeholder for when using keras pad_sequences\n",
    "\n",
    "vocab_len = len(vocabulary) + 1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to create vocabulary\n",
    "\n",
    "#from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "#tokenizer = Tokenizer(filters=[])\n",
    "\n",
    "#for text in [df.story.values,df.question.values,df.answer.values]:\n",
    "#    tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the maximum story length for padding seuqences\n",
    "\n",
    "max_story_len = max([len(tp[0]) for tp in data]) \n",
    "max_question_len = max([len(tp[1]) for tp in data]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(np.array([len(tp[0]) for tp in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoding words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index # lower-cased automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"story\":[' '.join(tp[0]) for tp in train],\"question\":[' '.join(tp[1]) for tp in train],\"answer\":[tp[2] for tp in train]}\n",
    "train_df = pd.DataFrame(train_dict)\n",
    "\n",
    "test_dict = {\"story\":[' '.join(tp[0]) for tp in test],\"question\":[' '.join(tp[1]) for tp in test],\"answer\":[tp[2] for tp in test]}\n",
    "test_df = pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Sandra in the hallway ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the office ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "1  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "2  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "3  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "4  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "\n",
       "                      question answer  \n",
       "0   Is Sandra in the hallway ?     no  \n",
       "1  Is Daniel in the bathroom ?     no  \n",
       "2    Is Daniel in the office ?     no  \n",
       "3   Is Daniel in the bedroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?    yes  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the kitchen ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the kitchen ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the garden ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary got the milk there . John moved to the be...   \n",
       "1  Mary got the milk there . John moved to the be...   \n",
       "2  Mary got the milk there . John moved to the be...   \n",
       "3  Mary got the milk there . John moved to the be...   \n",
       "4  Mary got the milk there . John moved to the be...   \n",
       "\n",
       "                      question answer  \n",
       "0     Is John in the kitchen ?     no  \n",
       "1     Is John in the kitchen ?     no  \n",
       "2      Is John in the garden ?    yes  \n",
       "3  Is Daniel in the bathroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?     no  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_story_and_questions(dframe, tokenizer):\n",
    "    \n",
    "    story = tokenizer.texts_to_sequences(dframe.story.values)\n",
    "    question = tokenizer.texts_to_sequences(dframe.question.values)\n",
    "\n",
    "    story = sequence.pad_sequences(story, maxlen=156)\n",
    "    question = sequence.pad_sequences(question, maxlen=6)\n",
    "    \n",
    "    return story, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train = compute_story_and_questions(train_df,tokenizer)\n",
    "inputs_test, questions_test = compute_story_and_questions(test_df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_answer(dframe):\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for yes_no in dframe.answer.values:\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)    \n",
    "        y[word_index[yes_no]] = 1\n",
    "        answers.append(y)\n",
    "    \n",
    "    return np.array(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_train = compute_answer(train_df)\n",
    "answers_test = compute_answer(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0., 4988.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0., 5012.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_train) # number of yes and no in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs ( story and question ) \n",
    "# creating placeholders for inputs\n",
    "\n",
    "input_sequence = Input(shape = (max_story_len,))\n",
    "input_question = Input(shape = (max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input encoders m, c and question encoder\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 156, 64)\n",
    "encoder_m = Sequential()\n",
    "encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=156))\n",
    "encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 156, 6)\n",
    "encoder_c = Sequential()\n",
    "encoder_c.add(Embedding(input_dim=vocab_len,output_dim=6,input_length=156))\n",
    "encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 6, 64)\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=6))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding sequences\n",
    "\n",
    "# passing place holders through encoders\n",
    "result_m = encoder_m(input_sequence) \n",
    "result_c = encoder_c(input_sequence)\n",
    "result_q = question_encoder(input_question)\n",
    "\n",
    "dt = dot([result_m, result_q], axes=(2, 2))\n",
    "p = Activation('softmax')(dt)\n",
    "\n",
    "# adding the p matrix with the input vector c sequence\n",
    "o = add([p, result_c])  # (samples, 156, 6)\n",
    "o = Permute((2, 1))(o)  # (samples, 6, 156)\n",
    "\n",
    "# concatenating the o matrix with the question vector sequence\n",
    "W = concatenate([o,result_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing W with RNN (LSTM)\n",
    "W = LSTM(32)(W)  \n",
    "\n",
    "# Regularization \n",
    "W = Dropout(0.5)(W)\n",
    "W = Dense(vocab_len)(W)  # (batch_size, vocab_size)\n",
    "\n",
    "# outputing a probability distribution over the vocabulary\n",
    "W = Activation('softmax')(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "model = Model([input_sequence, input_question], outputs = W)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 156, 64)      2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 156, 6)       228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WorkPC\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 4s 450us/step - loss: 0.8964 - accuracy: 0.4975 - val_loss: 0.7013 - val_accuracy: 0.5030\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 3s 343us/step - loss: 0.7037 - accuracy: 0.5004 - val_loss: 0.6944 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 4s 352us/step - loss: 0.6965 - accuracy: 0.4947 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 4s 351us/step - loss: 0.6954 - accuracy: 0.4914 - val_loss: 0.6972 - val_accuracy: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 4s 350us/step - loss: 0.6948 - accuracy: 0.4992 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 3s 349us/step - loss: 0.6948 - accuracy: 0.4949 - val_loss: 0.6932 - val_accuracy: 0.4920\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 3s 343us/step - loss: 0.6946 - accuracy: 0.4981 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 3s 348us/step - loss: 0.6948 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 4s 360us/step - loss: 0.6946 - accuracy: 0.4985 - val_loss: 0.6933 - val_accuracy: 0.4650\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.6943 - accuracy: 0.4983 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.6938 - accuracy: 0.5083 - val_loss: 0.6954 - val_accuracy: 0.4970\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.6936 - accuracy: 0.5069 - val_loss: 0.6935 - val_accuracy: 0.4850\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.6925 - accuracy: 0.5157 - val_loss: 0.6926 - val_accuracy: 0.5080\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.6868 - accuracy: 0.5364 - val_loss: 0.6852 - val_accuracy: 0.5540\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.6664 - accuracy: 0.5860 - val_loss: 0.6461 - val_accuracy: 0.6200\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.6399 - accuracy: 0.6314 - val_loss: 0.6193 - val_accuracy: 0.6540 - E\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.6271 - accuracy: 0.6465 - val_loss: 0.6012 - val_accuracy: 0.6800\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.6148 - accuracy: 0.6632 - val_loss: 0.5960 - val_accuracy: 0.6810\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.6044 - accuracy: 0.6732 - val_loss: 0.5842 - val_accuracy: 0.6810\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.5914 - accuracy: 0.6869 - val_loss: 0.5700 - val_accuracy: 0.6980\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.5776 - accuracy: 0.7040 - val_loss: 0.5581 - val_accuracy: 0.7180\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.5559 - accuracy: 0.7166 - val_loss: 0.5333 - val_accuracy: 0.7390\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.5361 - accuracy: 0.7353 - val_loss: 0.5312 - val_accuracy: 0.7310\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.5143 - accuracy: 0.7498 - val_loss: 0.4813 - val_accuracy: 0.7780\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.4917 - accuracy: 0.7678 - val_loss: 0.4662 - val_accuracy: 0.7900\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.4773 - accuracy: 0.7840 - val_loss: 0.4489 - val_accuracy: 0.7950\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.4505 - accuracy: 0.7996 - val_loss: 0.4555 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.4468 - accuracy: 0.8036 - val_loss: 0.4370 - val_accuracy: 0.8180\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.4266 - accuracy: 0.8181 - val_loss: 0.4218 - val_accuracy: 0.8170\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.4192 - accuracy: 0.8208 - val_loss: 0.4136 - val_accuracy: 0.8210\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.4064 - accuracy: 0.8241 - val_loss: 0.4090 - val_accuracy: 0.8140\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.4002 - accuracy: 0.8327 - val_loss: 0.4088 - val_accuracy: 0.8240\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3933 - accuracy: 0.8322 - val_loss: 0.4065 - val_accuracy: 0.8230\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3891 - accuracy: 0.8367 - val_loss: 0.4003 - val_accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.3849 - accuracy: 0.8360 - val_loss: 0.4095 - val_accuracy: 0.82103 - accuracy: 0.\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.3768 - accuracy: 0.8400 - val_loss: 0.4033 - val_accuracy: 0.8230\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3690 - accuracy: 0.8442 - val_loss: 0.4164 - val_accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3573 - accuracy: 0.8518 - val_loss: 0.4167 - val_accuracy: 0.8290\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3537 - accuracy: 0.8532 - val_loss: 0.3964 - val_accuracy: 0.8200\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3502 - accuracy: 0.8524 - val_loss: 0.3879 - val_accuracy: 0.8250\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3424 - accuracy: 0.8583 - val_loss: 0.3969 - val_accuracy: 0.8210\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.3439 - accuracy: 0.8557 - val_loss: 0.3766 - val_accuracy: 0.8270\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.3398 - accuracy: 0.8584 - val_loss: 0.3942 - val_accuracy: 0.8220\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3286 - accuracy: 0.8620 - val_loss: 0.3914 - val_accuracy: 0.8390\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.3342 - accuracy: 0.8602 - val_loss: 0.3862 - val_accuracy: 0.8320\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3333 - accuracy: 0.8623 - val_loss: 0.3939 - val_accuracy: 0.8280\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.3224 - accuracy: 0.8626 - val_loss: 0.3990 - val_accuracy: 0.8230\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3264 - accuracy: 0.8608 - val_loss: 0.3850 - val_accuracy: 0.8220\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.3168 - accuracy: 0.8663 - val_loss: 0.3761 - val_accuracy: 0.8300\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.3174 - accuracy: 0.8707 - val_loss: 0.3750 - val_accuracy: 0.8260\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3175 - accuracy: 0.8688 - val_loss: 0.3872 - val_accuracy: 0.8200\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3120 - accuracy: 0.8712 - val_loss: 0.3790 - val_accuracy: 0.82801s\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3148 - accuracy: 0.8664 - val_loss: 0.3823 - val_accuracy: 0.8360\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.3092 - accuracy: 0.8682 - val_loss: 0.3812 - val_accuracy: 0.8310\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3093 - accuracy: 0.8694 - val_loss: 0.3990 - val_accuracy: 0.8240\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3022 - accuracy: 0.8715 - val_loss: 0.3951 - val_accuracy: 0.8240\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3050 - accuracy: 0.8725 - val_loss: 0.3841 - val_accuracy: 0.8400\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.2986 - accuracy: 0.8760 - val_loss: 0.3946 - val_accuracy: 0.8360\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.3042 - accuracy: 0.8722 - val_loss: 0.3826 - val_accuracy: 0.8350\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.2957 - accuracy: 0.8766 - val_loss: 0.3899 - val_accuracy: 0.8270\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.2952 - accuracy: 0.8749 - val_loss: 0.4136 - val_accuracy: 0.8220\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.2983 - accuracy: 0.8735 - val_loss: 0.3836 - val_accuracy: 0.8330\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.2910 - accuracy: 0.8767 - val_loss: 0.3817 - val_accuracy: 0.8330\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2954 - accuracy: 0.8757 - val_loss: 0.3827 - val_accuracy: 0.8200\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2841 - accuracy: 0.8805 - val_loss: 0.3893 - val_accuracy: 0.8360\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.2895 - accuracy: 0.8777 - val_loss: 0.3877 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2830 - accuracy: 0.8808 - val_loss: 0.3859 - val_accuracy: 0.8370\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.2843 - accuracy: 0.8782 - val_loss: 0.3948 - val_accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.2774 - accuracy: 0.8833 - val_loss: 0.3936 - val_accuracy: 0.8300\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.2862 - accuracy: 0.8766 - val_loss: 0.3942 - val_accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2783 - accuracy: 0.8810 - val_loss: 0.3862 - val_accuracy: 0.8260\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2782 - accuracy: 0.8863 - val_loss: 0.4213 - val_accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2799 - accuracy: 0.8828 - val_loss: 0.4115 - val_accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2726 - accuracy: 0.8838 - val_loss: 0.4103 - val_accuracy: 0.8280\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2733 - accuracy: 0.8833 - val_loss: 0.4164 - val_accuracy: 0.8190\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2678 - accuracy: 0.8839 - val_loss: 0.4100 - val_accuracy: 0.8290\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.2686 - accuracy: 0.8888 - val_loss: 0.4078 - val_accuracy: 0.8230\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2645 - accuracy: 0.8846 - val_loss: 0.4485 - val_accuracy: 0.8240\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 4s 401us/step - loss: 0.2625 - accuracy: 0.8894 - val_loss: 0.4383 - val_accuracy: 0.8210\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.2624 - accuracy: 0.8894 - val_loss: 0.4222 - val_accuracy: 0.8280\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2679 - accuracy: 0.8858 - val_loss: 0.4161 - val_accuracy: 0.8210\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.2620 - accuracy: 0.8886 - val_loss: 0.4117 - val_accuracy: 0.8250\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.2603 - accuracy: 0.8887 - val_loss: 0.4400 - val_accuracy: 0.8140\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 4s 401us/step - loss: 0.2643 - accuracy: 0.8879 - val_loss: 0.4255 - val_accuracy: 0.8180\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2600 - accuracy: 0.8896 - val_loss: 0.4463 - val_accuracy: 0.8250\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2532 - accuracy: 0.8950 - val_loss: 0.4462 - val_accuracy: 0.8200\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2511 - accuracy: 0.8986 - val_loss: 0.4346 - val_accuracy: 0.8230\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2563 - accuracy: 0.8907 - val_loss: 0.4480 - val_accuracy: 0.8230\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.2520 - accuracy: 0.8956 - val_loss: 0.4440 - val_accuracy: 0.8100\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2554 - accuracy: 0.8951 - val_loss: 0.4557 - val_accuracy: 0.8180\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2468 - accuracy: 0.8959 - val_loss: 0.4486 - val_accuracy: 0.8210\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2478 - accuracy: 0.8955 - val_loss: 0.4545 - val_accuracy: 0.8200\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2493 - accuracy: 0.8949 - val_loss: 0.4461 - val_accuracy: 0.8160\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2431 - accuracy: 0.8971 - val_loss: 0.4456 - val_accuracy: 0.8240s: 0.2419 - accuracy - ETA: 0s - loss: 0.2416 - ac\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2408 - accuracy: 0.9000 - val_loss: 0.4725 - val_accuracy: 0.8160\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.2446 - accuracy: 0.8979 - val_loss: 0.4650 - val_accuracy: 0.8090\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2409 - accuracy: 0.8989 - val_loss: 0.4931 - val_accuracy: 0.8130\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2456 - accuracy: 0.8979 - val_loss: 0.4722 - val_accuracy: 0.8120\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2360 - accuracy: 0.8999 - val_loss: 0.4891 - val_accuracy: 0.8120\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2355 - accuracy: 0.9030 - val_loss: 0.4801 - val_accuracy: 0.8210\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[inputs_train,questions_train],\n",
    "                    y=answers_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "model.save(\"100_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predictions for test set\n",
    "predictions = model.predict(([inputs_test, questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "story       Mary got the milk there . John moved to the be...\n",
       "question                             Is John in the kitchen ?\n",
       "answer                                                     no\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of the answer:  0.99906737\n"
     ]
    }
   ],
   "source": [
    "# generating a prediction from model for first story/question/answer (test_df.iloc[0])\n",
    "val_max = np.argmax(predictions[0])\n",
    "\n",
    "for key, val in word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of the answer: \", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'left',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.',\n",
       " 'John',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hallway',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing our own cases, we must stick to the current vocabulary\n",
    "\n",
    "my_story = \"Mary left the bedroom . John dropped the football in the hallway .\"\n",
    "my_story.split() # punctuation is seperated as in format as it was trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'bedroom', '?']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question = \"Is the football in the bedroom ?\"\n",
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test cases. same format as our data (tuple)\n",
    "my_data = [(my_story.split(),my_question.split(),'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary left the bedroom . John dropped the footb...</td>\n",
       "      <td>Is the football in the bedroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary left the bedroom . John dropped the footb...   \n",
       "\n",
       "                           question answer  \n",
       "0  Is the football in the bedroom ?     no  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {\"story\":[' '.join(tp[0]) for tp in my_data],\n",
    "           \"question\":[' '.join(tp[1]) for tp in my_data],\n",
    "           \"answer\":[tp[2] for tp in my_data]}\n",
    "\n",
    "my_df = pd.DataFrame(my_dict)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story , my_question = compute_story_and_questions(my_df,tokenizer)\n",
    "my_answer = compute_answer(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        33,  4,  9,  6, 25, 34,  4, 22, 11,  4, 12,  6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 22, 11,  4,  9, 13]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of the answer:  0.99906737\n"
     ]
    }
   ],
   "source": [
    "my_prediction = model.predict(([my_story, my_question]))\n",
    "\n",
    "val_max = np.argmax(my_prediction[0])\n",
    "\n",
    "for key, val in word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of the answer: \", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
