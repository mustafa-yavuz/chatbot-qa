{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import text,sequence\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "\n",
    "with open(\"train.txt\", \"rb\") as f:   #list of tuples\n",
    "    train =  pickle.load(f)\n",
    "with open(\"test.txt\", \"rb\") as f:   \n",
    "    test =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test data into a dataframe\n",
    "data = train + test\n",
    "\n",
    "df_dict = {\"story\":[' '.join(tp[0]) for tp in data],\"question\":[' '.join(tp[1]) for tp in data],\"answer\":[tp[2] for tp in data]}\n",
    "df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Sandra in the hallway ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the office ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "1  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "2  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "3  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "4  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "\n",
       "                      question answer  \n",
       "0   Is Sandra in the hallway ?     no  \n",
       "1  Is Daniel in the bathroom ?     no  \n",
       "2    Is Daniel in the office ?     no  \n",
       "3   Is Daniel in the bedroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?    yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus to find vocabulary \n",
    "corpus = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    whole_text = df['story'][i] +' '+ df['question'][i] +' '+ df['answer'][i]\n",
    "    corpus.append(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using countvectorizer to find the vocabulary\n",
    "vectorizer = CountVectorizer(token_pattern = r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\.\")\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'sandra',\n",
       " 'journeyed',\n",
       " 'bedroom',\n",
       " 'is',\n",
       " 'in',\n",
       " 'hallway',\n",
       " '?',\n",
       " 'no',\n",
       " 'went',\n",
       " 'back',\n",
       " 'daniel',\n",
       " 'kitchen',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'football',\n",
       " 'there',\n",
       " 'yes',\n",
       " 'john',\n",
       " 'travelled',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'apple',\n",
       " 'put',\n",
       " 'down',\n",
       " 'grabbed',\n",
       " 'left',\n",
       " 'dropped',\n",
       " 'took',\n",
       " 'milk',\n",
       " 'discarded']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words in vocabulary\n",
    "list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a placeholder for when using keras pad_sequences\n",
    "\n",
    "vocab_len = len(vocabulary) + 1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to create vocabulary\n",
    "\n",
    "#from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "#tokenizer = Tokenizer(filters=[])\n",
    "\n",
    "#for text in [df.story.values,df.question.values,df.answer.values]:\n",
    "#    tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the maximum story length for padding seuqences\n",
    "\n",
    "max_story_len = max([len(tp[0]) for tp in data]) \n",
    "max_question_len = max([len(tp[1]) for tp in data]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(np.array([len(tp[0]) for tp in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encoding words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index # lower-cased automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"story\":[' '.join(tp[0]) for tp in train],\"question\":[' '.join(tp[1]) for tp in train],\"answer\":[tp[2] for tp in train]}\n",
    "train_df = pd.DataFrame(train_dict)\n",
    "\n",
    "test_dict = {\"story\":[' '.join(tp[0]) for tp in test],\"question\":[' '.join(tp[1]) for tp in test],\"answer\":[tp[2] for tp in test]}\n",
    "test_df = pd.DataFrame(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Sandra in the hallway ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the office ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary moved to the bathroom . Sandra journeyed ...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "1  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "2  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "3  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "4  Mary moved to the bathroom . Sandra journeyed ...   \n",
       "\n",
       "                      question answer  \n",
       "0   Is Sandra in the hallway ?     no  \n",
       "1  Is Daniel in the bathroom ?     no  \n",
       "2    Is Daniel in the office ?     no  \n",
       "3   Is Daniel in the bedroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?    yes  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the kitchen ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the kitchen ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is John in the garden ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is Daniel in the bathroom ?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mary got the milk there . John moved to the be...</td>\n",
       "      <td>Is Daniel in the bedroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary got the milk there . John moved to the be...   \n",
       "1  Mary got the milk there . John moved to the be...   \n",
       "2  Mary got the milk there . John moved to the be...   \n",
       "3  Mary got the milk there . John moved to the be...   \n",
       "4  Mary got the milk there . John moved to the be...   \n",
       "\n",
       "                      question answer  \n",
       "0     Is John in the kitchen ?     no  \n",
       "1     Is John in the kitchen ?     no  \n",
       "2      Is John in the garden ?    yes  \n",
       "3  Is Daniel in the bathroom ?    yes  \n",
       "4   Is Daniel in the bedroom ?     no  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_story_and_questions(dframe, tokenizer):\n",
    "    \n",
    "    story = tokenizer.texts_to_sequences(dframe.story.values)\n",
    "    question = tokenizer.texts_to_sequences(dframe.question.values)\n",
    "\n",
    "    story = sequence.pad_sequences(story, maxlen=156)\n",
    "    question = sequence.pad_sequences(question, maxlen=6)\n",
    "    \n",
    "    return story, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train = compute_story_and_questions(train_df,tokenizer)\n",
    "inputs_test, questions_test = compute_story_and_questions(test_df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_answer(dframe):\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    for yes_no in dframe.answer.values:\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)    \n",
    "        y[word_index[yes_no]] = 1\n",
    "        answers.append(y)\n",
    "    \n",
    "    return np.array(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_train = compute_answer(train_df)\n",
    "answers_test = compute_answer(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0., 4988.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0., 5012.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_train) # number of yes and no in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs ( story and question ) \n",
    "# creating placeholders for inputs\n",
    "\n",
    "input_sequence = Input(shape = (max_story_len,))\n",
    "input_question = Input(shape = (max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating input encoders m, c and question encoder\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 156, 64)\n",
    "encoder_m = Sequential()\n",
    "encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=156))\n",
    "encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 156, 6)\n",
    "encoder_c = Sequential()\n",
    "encoder_c.add(Embedding(input_dim=vocab_len,output_dim=6,input_length=156))\n",
    "encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# output of input_encoder_m in the format of (batch_size, 6, 64)\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=6))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding sequences\n",
    "\n",
    "# passing place holders through encoders\n",
    "result_m = encoder_m(input_sequence) \n",
    "result_c = encoder_c(input_sequence)\n",
    "result_q = question_encoder(input_question)\n",
    "\n",
    "dt = dot([result_m, result_q], axes=(2, 2))\n",
    "p = Activation('softmax')(dt)\n",
    "\n",
    "# adding the p matrix with the input vector c sequence\n",
    "o = add([p, result_c])  # (samples, 156, 6)\n",
    "o = Permute((2, 1))(o)  # (samples, 6, 156)\n",
    "\n",
    "# concatenating the o matrix with the question vector sequence\n",
    "W = concatenate([o,result_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing W with RNN (LSTM)\n",
    "W = LSTM(32)(W)  \n",
    "\n",
    "# Regularization \n",
    "W = Dropout(0.5)(W)\n",
    "W = Dense(vocab_len)(W)  # (batch_size, vocab_size)\n",
    "\n",
    "# outputing a probability distribution over the vocabulary\n",
    "W = Activation('softmax')(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "model = Model([input_sequence, input_question], outputs = W)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 156, 64)      2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 156, 6)       228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WorkPC\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.9524 - accuracy: 0.4970 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 3s 336us/step - loss: 0.7085 - accuracy: 0.5001 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 3s 335us/step - loss: 0.6969 - accuracy: 0.4993 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 3s 335us/step - loss: 0.6950 - accuracy: 0.5006 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 3s 335us/step - loss: 0.6946 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 3s 335us/step - loss: 0.6944 - accuracy: 0.5052 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 3s 335us/step - loss: 0.6945 - accuracy: 0.5002 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 3s 334us/step - loss: 0.6947 - accuracy: 0.4959 - val_loss: 0.6940 - val_accuracy: 0.4840\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 3s 336us/step - loss: 0.6937 - accuracy: 0.5078 - val_loss: 0.6946 - val_accuracy: 0.4810\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 4s 366us/step - loss: 0.6930 - accuracy: 0.5094 - val_loss: 0.6975 - val_accuracy: 0.4810\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.6901 - accuracy: 0.5210 - val_loss: 0.6953 - val_accuracy: 0.5330\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.6821 - accuracy: 0.5473 - val_loss: 0.6820 - val_accuracy: 0.5570\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.6678 - accuracy: 0.5937 - val_loss: 0.6560 - val_accuracy: 0.6180\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.6458 - accuracy: 0.6309 - val_loss: 0.6365 - val_accuracy: 0.6610\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.6241 - accuracy: 0.6587 - val_loss: 0.6158 - val_accuracy: 0.6420\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.6062 - accuracy: 0.6783 - val_loss: 0.5684 - val_accuracy: 0.7170\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.5676 - accuracy: 0.7103 - val_loss: 0.5527 - val_accuracy: 0.7260\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.5337 - accuracy: 0.7425 - val_loss: 0.4992 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.4939 - accuracy: 0.7735 - val_loss: 0.4664 - val_accuracy: 0.7930\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.4817 - accuracy: 0.7830 - val_loss: 0.4502 - val_accuracy: 0.8040\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.4632 - accuracy: 0.7950 - val_loss: 0.4539 - val_accuracy: 0.7980\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.4485 - accuracy: 0.8055 - val_loss: 0.4454 - val_accuracy: 0.8030\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.4365 - accuracy: 0.8085 - val_loss: 0.4513 - val_accuracy: 0.8060\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.4301 - accuracy: 0.8140 - val_loss: 0.4329 - val_accuracy: 0.8030\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.4180 - accuracy: 0.8199 - val_loss: 0.4740 - val_accuracy: 0.8070\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.4127 - accuracy: 0.8260 - val_loss: 0.4316 - val_accuracy: 0.7970\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.4026 - accuracy: 0.8295 - val_loss: 0.4354 - val_accuracy: 0.7970\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3976 - accuracy: 0.8291 - val_loss: 0.4249 - val_accuracy: 0.8040\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3908 - accuracy: 0.8337 - val_loss: 0.4147 - val_accuracy: 0.8130\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3879 - accuracy: 0.8372 - val_loss: 0.4097 - val_accuracy: 0.8220\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3787 - accuracy: 0.8379 - val_loss: 0.4106 - val_accuracy: 0.8250\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.3723 - accuracy: 0.8430 - val_loss: 0.4126 - val_accuracy: 0.8180\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.3744 - accuracy: 0.8431 - val_loss: 0.4031 - val_accuracy: 0.8310\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.3685 - accuracy: 0.8456 - val_loss: 0.4024 - val_accuracy: 0.8100\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3626 - accuracy: 0.8476 - val_loss: 0.4176 - val_accuracy: 0.8220\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3611 - accuracy: 0.8484 - val_loss: 0.4102 - val_accuracy: 0.8160\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3618 - accuracy: 0.8472 - val_loss: 0.3964 - val_accuracy: 0.8320\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3514 - accuracy: 0.8528 - val_loss: 0.4095 - val_accuracy: 0.8280\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3512 - accuracy: 0.8500 - val_loss: 0.3921 - val_accuracy: 0.8300\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3515 - accuracy: 0.8508 - val_loss: 0.3967 - val_accuracy: 0.8290\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3449 - accuracy: 0.8540 - val_loss: 0.3960 - val_accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3423 - accuracy: 0.8568 - val_loss: 0.4022 - val_accuracy: 0.8340\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3391 - accuracy: 0.8579 - val_loss: 0.3996 - val_accuracy: 0.8290\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.3412 - accuracy: 0.8535 - val_loss: 0.3941 - val_accuracy: 0.8290\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3415 - accuracy: 0.8571 - val_loss: 0.4005 - val_accuracy: 0.8230\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3350 - accuracy: 0.8557 - val_loss: 0.4056 - val_accuracy: 0.8140\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3317 - accuracy: 0.8576 - val_loss: 0.4180 - val_accuracy: 0.8120\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3356 - accuracy: 0.8582 - val_loss: 0.3982 - val_accuracy: 0.8260\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3272 - accuracy: 0.8583 - val_loss: 0.3953 - val_accuracy: 0.8370\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.3257 - accuracy: 0.8641 - val_loss: 0.3929 - val_accuracy: 0.8230\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3266 - accuracy: 0.8559 - val_loss: 0.3909 - val_accuracy: 0.8350\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3207 - accuracy: 0.8632 - val_loss: 0.3857 - val_accuracy: 0.8300\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3174 - accuracy: 0.8650 - val_loss: 0.3916 - val_accuracy: 0.8320\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3201 - accuracy: 0.8636 - val_loss: 0.3876 - val_accuracy: 0.8290\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3163 - accuracy: 0.8655 - val_loss: 0.4007 - val_accuracy: 0.8240\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3151 - accuracy: 0.8625 - val_loss: 0.3904 - val_accuracy: 0.8310\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3153 - accuracy: 0.8689 - val_loss: 0.3996 - val_accuracy: 0.8300\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3131 - accuracy: 0.8633 - val_loss: 0.3819 - val_accuracy: 0.8350\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3057 - accuracy: 0.8715 - val_loss: 0.4116 - val_accuracy: 0.8170\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.3124 - accuracy: 0.8649 - val_loss: 0.3995 - val_accuracy: 0.8280\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3041 - accuracy: 0.8697 - val_loss: 0.3860 - val_accuracy: 0.8220\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3069 - accuracy: 0.8663 - val_loss: 0.3986 - val_accuracy: 0.8290\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3067 - accuracy: 0.8683 - val_loss: 0.3997 - val_accuracy: 0.8310\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.3040 - accuracy: 0.8680 - val_loss: 0.3916 - val_accuracy: 0.8240\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.3008 - accuracy: 0.8713 - val_loss: 0.3997 - val_accuracy: 0.8350\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2970 - accuracy: 0.8698 - val_loss: 0.3960 - val_accuracy: 0.8280\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.2940 - accuracy: 0.8761 - val_loss: 0.4173 - val_accuracy: 0.8220\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.3010 - accuracy: 0.8710 - val_loss: 0.4257 - val_accuracy: 0.8270\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2916 - accuracy: 0.8756 - val_loss: 0.4079 - val_accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.2926 - accuracy: 0.8741 - val_loss: 0.4023 - val_accuracy: 0.8330\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2864 - accuracy: 0.8740 - val_loss: 0.4081 - val_accuracy: 0.8410\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2880 - accuracy: 0.8784 - val_loss: 0.4217 - val_accuracy: 0.8280\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2828 - accuracy: 0.8770 - val_loss: 0.4142 - val_accuracy: 0.8190\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.2859 - accuracy: 0.8804 - val_loss: 0.4270 - val_accuracy: 0.8300\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2805 - accuracy: 0.8805 - val_loss: 0.4138 - val_accuracy: 0.8370\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2830 - accuracy: 0.8786 - val_loss: 0.4104 - val_accuracy: 0.8150\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2813 - accuracy: 0.8815 - val_loss: 0.4212 - val_accuracy: 0.8350\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2813 - accuracy: 0.8809 - val_loss: 0.4367 - val_accuracy: 0.8350\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2772 - accuracy: 0.8827 - val_loss: 0.4275 - val_accuracy: 0.8370\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2750 - accuracy: 0.8838 - val_loss: 0.4298 - val_accuracy: 0.8380\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2761 - accuracy: 0.8789 - val_loss: 0.4080 - val_accuracy: 0.8330\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2748 - accuracy: 0.8851 - val_loss: 0.4149 - val_accuracy: 0.82801 - accura\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2786 - accuracy: 0.8833 - val_loss: 0.4317 - val_accuracy: 0.8270\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2760 - accuracy: 0.8828 - val_loss: 0.4428 - val_accuracy: 0.8240\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2743 - accuracy: 0.8871 - val_loss: 0.4274 - val_accuracy: 0.8270\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2682 - accuracy: 0.8871 - val_loss: 0.4441 - val_accuracy: 0.8230\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2692 - accuracy: 0.8832 - val_loss: 0.4397 - val_accuracy: 0.8230s: 0.270\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2599 - accuracy: 0.8887 - val_loss: 0.4697 - val_accuracy: 0.8280\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2625 - accuracy: 0.8906 - val_loss: 0.4436 - val_accuracy: 0.8340\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2583 - accuracy: 0.8901 - val_loss: 0.4422 - val_accuracy: 0.8350\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2596 - accuracy: 0.8926 - val_loss: 0.4635 - val_accuracy: 0.8290\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2566 - accuracy: 0.8902 - val_loss: 0.4816 - val_accuracy: 0.8200\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2580 - accuracy: 0.8915 - val_loss: 0.4686 - val_accuracy: 0.8210\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2554 - accuracy: 0.8896 - val_loss: 0.4615 - val_accuracy: 0.8230\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2567 - accuracy: 0.8928 - val_loss: 0.4859 - val_accuracy: 0.8260\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2566 - accuracy: 0.8920 - val_loss: 0.4724 - val_accuracy: 0.8250\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2527 - accuracy: 0.8941 - val_loss: 0.4633 - val_accuracy: 0.8210\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2500 - accuracy: 0.8966 - val_loss: 0.5179 - val_accuracy: 0.8160\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2496 - accuracy: 0.8970 - val_loss: 0.4950 - val_accuracy: 0.8250\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.2539 - accuracy: 0.8917 - val_loss: 0.4730 - val_accuracy: 0.8270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[inputs_train,questions_train],\n",
    "                    y=answers_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "model.save(\"100_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predictions for test set\n",
    "predictions = model.predict(([inputs_test, questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "story       Mary got the milk there . John moved to the be...\n",
       "question                             Is John in the kitchen ?\n",
       "answer                                                     no\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of the answer:  0.9998734\n"
     ]
    }
   ],
   "source": [
    "# generating a prediction from model for first story/question/answer (test_df.iloc[0])\n",
    "val_max = np.argmax(predictions[0])\n",
    "\n",
    "for key, val in word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of the answer: \", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'left',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.',\n",
       " 'John',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hallway',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing our own cases, we must stick to the current vocabulary\n",
    "\n",
    "my_story = \"Mary left the bedroom . John dropped the football in the hallway .\"\n",
    "my_story.split() # punctuation is seperated as in format as it was trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'bedroom', '?']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question = \"Is the football in the bedroom ?\"\n",
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test cases. same format as our data (tuple)\n",
    "my_data = [(my_story.split(),my_question.split(),'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mary left the bedroom . John dropped the footb...</td>\n",
       "      <td>Is the football in the bedroom ?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  Mary left the bedroom . John dropped the footb...   \n",
       "\n",
       "                           question answer  \n",
       "0  Is the football in the bedroom ?     no  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {\"story\":[' '.join(tp[0]) for tp in my_data],\n",
    "           \"question\":[' '.join(tp[1]) for tp in my_data],\n",
    "           \"answer\":[tp[2] for tp in my_data]}\n",
    "\n",
    "my_df = pd.DataFrame(my_dict)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story , my_question = compute_story_and_questions(my_df,tokenizer)\n",
    "my_answer = compute_answer(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        33,  4,  9,  6, 25, 34,  4, 22, 11,  4, 12,  6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 22, 11,  4,  9, 13]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of the answer:  0.9998734\n"
     ]
    }
   ],
   "source": [
    "my_prediction = model.predict(([my_story, my_question]))\n",
    "\n",
    "val_max = np.argmax(my_prediction[0])\n",
    "\n",
    "for key, val in word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of the answer: \", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
